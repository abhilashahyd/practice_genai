{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Set up your OpenAI API key\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_video_id(youtube_url):\n",
    "    video_id_regex = r'(?:v=|\\/)([0-9A-Za-z_-]{11}).*'\n",
    "    match = re.search(video_id_regex, youtube_url)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "def get_transcript(video_id):\n",
    "    try:\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "        text_list = [item['text'] for item in transcript]\n",
    "        transcript_text = '\\n'.join(text_list)\n",
    "        return transcript_text\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "def summarize_transcript(transcript_text):\n",
    "    openai.api_key = os.environ['OPENAI_API_KEY']  # Replace with your OpenAI API key\n",
    "    prompt = f\"Please summarize the following text:\\n\\n{transcript_text}\"\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4o-mini\",  # Use the appropriate model\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=1150  # Adjust token limit as needed\n",
    "    )\n",
    "    \n",
    "    summary = response.choices[0].message['content']\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_youtube_video(youtube_url):\n",
    "    video_id = extract_video_id(youtube_url)\n",
    "    if video_id:\n",
    "        transcript_text = get_transcript(video_id)\n",
    "        if transcript_text:\n",
    "            summary = summarize_transcript(transcript_text)\n",
    "            return summary\n",
    "    return \"Unable to summarize the video.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walking Tree is an innovative company specializing in designing and deploying advanced cross-platform web and mobile applications. They focus on seamless data integration, analytics, and modernizing legacy systems. Their mission is to partner with businesses to enhance their digital transformation initiatives through tailored business intelligence solutions.\n",
      "\n",
      "During a recent session, the company discussed effective strategies for building intelligent applications using language models (LLMs). They highlighted the importance of incorporating LLMs into apps, acknowledging that while LLMs offer significant advantages, their full potential is realized only when integrated thoughtfully with existing systems and data sources. \n",
      "\n",
      "The presentation featured industry experts discussing various aspects of LLMs, including selecting the right models, integrating them into applications, and ensuring effective prompt engineering to maximize results. Different frameworks like LangChain and Haystack were mentioned for application development, emphasizing their role in managing data processing, maintaining context in conversations, and improving overall application structure.\n",
      "\n",
      "Walkthroughs of popular LLM applications like ChatGPT and Google Bard were discussed, illustrating the different capabilities and use cases. Various criteria for selecting models were outlined, such as accuracy, speed, cost, and domain-specific needs. Furthermore, a framework for evaluating LLM performance, known as HELM (Holistic Evaluation of Language Models), was presented, highlighting the need for continuous improvement and evaluation of model outputs.\n",
      "\n",
      "The session concluded with a Q&A segment that addressed several inquiries about handling vector data, PDF layout processing, and managing toxicity in model responses, emphasizing the importance of structured prompts and model fine-tuning to achieve accurate and appropriate outputs.\n"
     ]
    }
   ],
   "source": [
    "youtube_url = 'https://www.youtube.com/watch?v=1FhuvIuIIvg&list=PLBZRs2RzeAlr99JPvD5swEFi3eUwRGME2&index=9'\n",
    "summary = summarize_youtube_video(youtube_url)\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "so welcome to those discovering walking\n",
      "tree for the very first time\n",
      "uh walking tree stands as a Vanguard of\n",
      "Technology driven Innovation\n",
      "specializing in the design and\n",
      "deployment of Cutting Edge cross\n",
      "platform web and mobile applications we\n",
      "are not just a company but a coalition\n",
      "of Visionaries and Pioneers passionately\n",
      "dedicated to facilitating\n",
      "seamless system Integrations and\n",
      "accelerating momentum of digital\n",
      "transformation initiatives\n",
      "our core expertise lies in Advanced Data\n",
      "integration analytics and the transition\n",
      "of Legacy systems to contemporary high\n",
      "performance platforms\n",
      "armed with a comprehensive Suite of\n",
      "business intelligence Solutions spanning\n",
      "across various domains we are uniquely\n",
      "positioned to empower businesses\n",
      "are bespoke solutions cater to the\n",
      "intricate data Centric needs of our\n",
      "clients offering them the agility and\n",
      "the efficiency they require in today's\n",
      "competitive business landscape\n",
      "at walking tree we strive to be not just\n",
      "service providers but trusted Partners\n",
      "in your digital Journey offering\n",
      "industrial leading expertise and\n",
      "Technology you know technological\n",
      "innovation to reshape your business for\n",
      "the future\n",
      "I see quite a few familiar faces so very\n",
      "uh very warm welcome back to all of you\n",
      "from the previous sessions on generative\n",
      "AI\n",
      "your continued presence underscores the\n",
      "value you derive from these sessions and\n",
      "we couldn't be uh more pleased today we\n",
      "speak on the best strategies to navigate\n",
      "LM landscape for building intelligent\n",
      "apps\n",
      "llms have emerged as a Force Major in\n",
      "the world of knowledge generation and\n",
      "reasoning increasingly viewed as a\n",
      "transformative tool for developers\n",
      "aspiring to create hither to\n",
      "unachievable Applications\n",
      "however a sole Reliance on elements may\n",
      "not suffice in the Quest for truly\n",
      "impactful apps\n",
      "uh the true potential of these\n",
      "Technologies and Pearls when they are\n",
      "judicially integrated\n",
      "and our distinguished speakers will\n",
      "illuminate on this topic further we have\n",
      "reserved some time towards the end for\n",
      "your questions\n",
      "so I encourage you to drop them in the Q\n",
      "a box throughout the webinar\n",
      "so let's all harness our collective\n",
      "intelligence presence today for a richer\n",
      "and more informed discussion we look\n",
      "forward to your active participation\n",
      "I will now introduce our speakers of the\n",
      "day we have Scott who has over 30 years\n",
      "of experience and has been an astute\n",
      "Problem Solver entrepreneur and\n",
      "Technology leader driving our\n",
      "organization\n",
      "towards a diverse range of digital and\n",
      "data analytics capabilities and a\n",
      "culture of client-centric innovation\n",
      "in addition to his invaluable guidance\n",
      "and insight Scott actively shares his\n",
      "knowledge to the clients and the working\n",
      "train a walking tree team empowering\n",
      "them to confidently navigate challenges\n",
      "leverage opportunities and fuel\n",
      "Innovative growth\n",
      "we have abhilasha whose illustrious\n",
      "career spans over two decades during\n",
      "which she has led High performing teams\n",
      "in the development of Enterprise scale\n",
      "products and applications\n",
      "her expertise includes over a decade of\n",
      "experience in driving the end-to-end\n",
      "design and development of complex\n",
      "analytics solutions for diverse industry\n",
      "segments\n",
      "abilasha's unwavering commitment to\n",
      "Excellence coupled with a deep\n",
      "understanding of Technology landscape as\n",
      "under a reputation as a series leader in\n",
      "the field\n",
      "you also have with us a shubham\n",
      "bharadwaj with a robust background in\n",
      "data engineering artificial intelligence\n",
      "machine learning nlps and kubernetes\n",
      "shubham is a seasoned senior software\n",
      "engineer with over four years of\n",
      "Industry experience now\n",
      "he has a proven track record of\n",
      "Designing flutter GPT 3 based\n",
      "applications building applications that\n",
      "leverage machine learning services on\n",
      "AWS to process videos images audio and\n",
      "text creating a cutting-edge ml Ops\n",
      "platform that addresses the limitations\n",
      "of existing platforms\n",
      "now before we get on to today's agenda I\n",
      "just\n",
      "quick reminder we will be answering all\n",
      "your questions towards the end of the\n",
      "session so please\n",
      "leave them in the Q a result\n",
      "I'll just end\n",
      "over the session to our speakers so just\n",
      "please bear with me once\n",
      "thankfully I can see a few more people\n",
      "joining in so right here we are hello\n",
      "Scott\n",
      "pretty\n",
      "hey Prince you how are you doing I'm\n",
      "good how about you hey doing great thank\n",
      "you\n",
      "very good well thank you for the uh for\n",
      "the introduction and uh Prince you what\n",
      "I'll do I'll uh if you want to yeah if\n",
      "you want to share that's fine too\n",
      "um so today what I'll do is I'll kind of\n",
      "set the stage for us a bit and you know\n",
      "talk about uh really talk about you know\n",
      "the different\n",
      "um\n",
      "you know the different options you have\n",
      "and then how to select a bit and then\n",
      "from there we'll go into really some\n",
      "more detail and then and then end up\n",
      "with maybe a demo of of some of these uh\n",
      "some of these models so\n",
      "um so if you'll go to the agenda slide\n",
      "um French use that would be great\n",
      "all right thank you so like I said we'll\n",
      "we'll talk about first about the open\n",
      "and closed source llms and uh I won't\n",
      "spend a ton of time uh because I think\n",
      "we want to get to more of the\n",
      "integrating those llms and then\n",
      "um you know the apps designing the the\n",
      "app's designing the uh using the\n",
      "different llms but we'll talk a little\n",
      "bit about open closed source and then\n",
      "selecting\n",
      "um really the model that best suits your\n",
      "needs and then I'll turn it over to\n",
      "abalasha after that to talk about\n",
      "integrating llms and applications and\n",
      "then the shubham will uh talk uh in\n",
      "regards to apps designed using different\n",
      "LMS so that's kind of the structure and\n",
      "the agenda of a call\n",
      "so with that we'll talk about open and\n",
      "closed source llms and there are several\n",
      "big players in this space\n",
      "um you know some of them you're probably\n",
      "very well familiar with and the metas\n",
      "and the Microsoft and videos and of\n",
      "course open AI\n",
      "um and then you know we have others as\n",
      "well like cohere uh you know an\n",
      "anthropic and uh of course Google in\n",
      "that space as well so we'll talk through\n",
      "some of those look at some of the maybe\n",
      "the advantages and uh challenges uh for\n",
      "each of those so uh first let's look at\n",
      "the closed Source or the proprietary\n",
      "options right and we will share this\n",
      "deck by the way uh but just to give you\n",
      "an idea of a few of these uh and really\n",
      "kind of how we go about looking at them\n",
      "from a walking tree standpoint anyway\n",
      "and it really that's based on a how many\n",
      "parameters are they trained with what's\n",
      "the context the the training what's the\n",
      "quality the speed because and fine-tune\n",
      "ability so all those things will come\n",
      "into play when you are selecting a model\n",
      "to uh you know to use for your\n",
      "application right so uh so just because\n",
      "one is maybe really good at quality\n",
      "maybe the speed is not so good so\n",
      "there's some trade-off you can do and\n",
      "maybe even need to have some fine tuning\n",
      "in there as well so\n",
      "um but you know of course the latest one\n",
      "from open AI is gpt4 uh really good\n",
      "quality at the moment the speed maybe is\n",
      "not as as good as some of the others but\n",
      "uh certainly if you're looking for\n",
      "Quality uh you know that's uh that\n",
      "that's definitely you know the top one\n",
      "as far as that goes of course gpt3 GPT\n",
      "3.5 turbo which is what many of us have\n",
      "been using for a while now that's still\n",
      "very good quality uh you know and then\n",
      "with maybe a little little slower speed\n",
      "but if you're looking at something with\n",
      "uh really decent speed decent quality\n",
      "then you've got Claude and and then on\n",
      "Down the Line really there's others you\n",
      "know like uh bab Edge and Curie and so\n",
      "forth as well as command Medium as well\n",
      "so some of those are really fast and and\n",
      "have good fine-tune ability so so again\n",
      "you really want to look at each of these\n",
      "and just see what's what's most\n",
      "important so what we try to do here is\n",
      "kind of gauge that and give you a little\n",
      "gauge on what's most important to you\n",
      "right so that way it'll help you kind of\n",
      "uh go through and look at what might be\n",
      "best so but that's from a closed Source\n",
      "options okay and then let's start\n",
      "looking at the open source options right\n",
      "and you know with any open source that\n",
      "you use right whether it's in this space\n",
      "or\n",
      "libraries or just in general software in\n",
      "general right\n",
      "so what are the variations uh you know\n",
      "there's permissive licenses like Apache\n",
      "2.0 that you know more or less do what\n",
      "allow you to do what you want to do with\n",
      "a model and then there's a restricted\n",
      "license and uh you know there's\n",
      "restrictions that come with that right\n",
      "on a commercial use for for the software\n",
      "but they don't prohibit it necessarily\n",
      "right so and that one we say draw your\n",
      "own conclusions whether this works for\n",
      "you or not and and that's not a negative\n",
      "it's just hey you you have to decide if\n",
      "that's important to you or not depending\n",
      "on uh the application that you're\n",
      "developing and then of course there's\n",
      "the non-commercial licenses like like\n",
      "Facebook's proprietary ones or or maybe\n",
      "a creative comments uh that it really\n",
      "explicitly prohibit commercial use and\n",
      "you know those are not really a good\n",
      "choice right for building apps on\n",
      "okay and then just from again just like\n",
      "we did with a close uh Source or\n",
      "proprietary options uh you can kind of\n",
      "see from an open source standpoint you\n",
      "know what's available to you like Google\n",
      "AI\n",
      "and uh you know Elektra and stability Ai\n",
      "and meta and so on if you look again you\n",
      "got to look at what's important to you\n",
      "licensing wise\n",
      "um you know is having a just a pure open\n",
      "2.0 Apache 2.0 uh option available to\n",
      "you the most important thing uh or maybe\n",
      "uh you know maybe you can you can deal\n",
      "with having a more you know more\n",
      "restricted license right so again this\n",
      "chart\n",
      "um I'm not going to talk through every\n",
      "single one of these but you know again\n",
      "just to give you an idea when you're\n",
      "looking at these you kind of know and\n",
      "you can kind of Wade through your\n",
      "options on uh on what might work best\n",
      "for you okay well what about selecting\n",
      "the model that that uh that suits you\n",
      "best\n",
      "so with that\n",
      "um what are the things to really think\n",
      "about when you go into selecting the\n",
      "right model\n",
      "and if we look at this from the options\n",
      "uh you got off-the-shelf models like\n",
      "open Ai cohere and then you've got uh\n",
      "customizable and then you could or you\n",
      "could train your own well let's look at\n",
      "off-the-shelf models like open AI first\n",
      "so when in that options basically what\n",
      "do you do you subscribe to use it uh\n",
      "utilization of the existing\n",
      "off-the-shelf tools you can really you\n",
      "know harness the power of a pre-existing\n",
      "llm right so it's there it's uh it\n",
      "already has had training and it's there\n",
      "and it's ready to use so it's easy and\n",
      "Advantage wise it's easy to get started\n",
      "and again it's an existing model that\n",
      "you can use for generic use a use case\n",
      "right uh maybe uh you know maybe it's a\n",
      "good use case for like text to SQL and\n",
      "have knowledge behind that right\n",
      "maybe you need to do maybe it's a good\n",
      "option if maybe you need to do prompt\n",
      "engineering right using zero one or two\n",
      "uh or one or a few you know short\n",
      "learnings so one of the disadvantages of\n",
      "that\n",
      "um no domain knowledge so the models out\n",
      "there it's developed it's got a lot of\n",
      "information but it may not you know\n",
      "probably won't know about your specific\n",
      "domain right so and again with that too\n",
      "you're tied to a provider and uh you\n",
      "know it could result in hallucinations\n",
      "right so you may get something back\n",
      "that's like wow that's not really even\n",
      "in the ballpark\n",
      "um\n",
      "well if not an open shift model then\n",
      "let's look at the customizable ones\n",
      "right so what are some of the options\n",
      "there well one is you can consume them\n",
      "with using guard rails right so you can\n",
      "buy guard rails those could be whether\n",
      "it's putting guard rounds guard rails\n",
      "around the topics or maybe it's a safety\n",
      "issue you're trying to protect against\n",
      "certain words and and and phrases and\n",
      "those kind of things being used or maybe\n",
      "it's a security issue so but but you can\n",
      "Implement guard rails with those so\n",
      "that's one form of customization is\n",
      "using guardrails well\n",
      "you know what's the advantage of that\n",
      "um you know it it can help you know it\n",
      "can help uh reduce hallucinations and\n",
      "and bring structure right to uh to your\n",
      "model disadvantages with that is so\n",
      "you're still you're tied to a provider\n",
      "with that so if you're using guard rails\n",
      "whatever uh whatever company you're\n",
      "using that with you're tied to a\n",
      "provider right so\n",
      "um the next form of customization might\n",
      "be that you you augment right so maybe\n",
      "you take maybe you've got a database\n",
      "that you leverage to do lookups to\n",
      "customize the llm uh really according to\n",
      "your requirements right or what's\n",
      "specific to your organization and that\n",
      "that is really the advantage right is\n",
      "that you augment the llm with the with\n",
      "domain knowledge\n",
      "and again the disadvantage of that is\n",
      "you're tied to a certain provider and\n",
      "then what's the other customizable\n",
      "option maybe uh maybe fine tune right so\n",
      "fine-tuning\n",
      "uh it's where you you know the user\n",
      "finds fine tunes or tailors the llm city\n",
      "orgs needs and that's nice and the\n",
      "advantage of that is that that you can\n",
      "influence the behavior of the model uh\n",
      "by means of that fine-tuning with a\n",
      "specific data set right uh really the\n",
      "disadvantage to that is it's just\n",
      "additional uh cost and tuning and usage\n",
      "right uh but again it's weighing out\n",
      "those things maybe that's important\n",
      "maybe the cost is uh maybe the cost is\n",
      "okay it's it's something that you can\n",
      "absorb because you're getting good value\n",
      "out of that so uh and then lastly uh\n",
      "training your own model right so build\n",
      "and train your own model from scratch\n",
      "with your data that gives you absolute\n",
      "complete control on data and models uh\n",
      "the disadvantage to that of course is\n",
      "it's complicated it's time consuming and\n",
      "it can be really really expensive\n",
      "okay\n",
      "um well what about choosing your model\n",
      "based uh your you know what are our\n",
      "recommendations right so when you choose\n",
      "a model kind of what are some of the\n",
      "things that we might recommend to you\n",
      "well you know most projects can start\n",
      "with like gpt4 and that's just a real\n",
      "good place to start with a proof of\n",
      "concept or the feasibility of the task\n",
      "you're trying to uh to perform\n",
      "um well you know if cost is a factor\n",
      "there you know consider downsizing right\n",
      "gpt3 and clot are really good choices\n",
      "and they have comparable performance and\n",
      "I would say that if um\n",
      "you know if your aim is increased speed\n",
      "and cost efficiency really you know any\n",
      "of these providers will suffice for you\n",
      "that although the anthropic option\n",
      "really sends out it's really a good a\n",
      "good option uh you know and and really\n",
      "the most contemporary choice if you need\n",
      "fine tuning consider cohere uh if you\n",
      "need to open source OSS if you use that\n",
      "if you really need it right but you can\n",
      "see back in that chart some of the some\n",
      "of the advantages and disadvantages of\n",
      "using that using an open source um so\n",
      "but again it's everything needs to be\n",
      "weighed out right and maybe there's the\n",
      "times and and ways that you can mix and\n",
      "match and use use them for use a\n",
      "combination even\n",
      "okay next\n",
      "okay and with that\n",
      "um just again just a brief summary of of\n",
      "the different types of Open Source uh\n",
      "those are the main one that we've the\n",
      "ones we've highlighted are really the\n",
      "major ones that are are being used uh\n",
      "and then you know again just some very\n",
      "uh General guidelines when you start to\n",
      "develop your models and what when you're\n",
      "selecting what model you're going to use\n",
      "so with that I'm going to actually turn\n",
      "this over to abalasha and abalashia can\n",
      "uh can get us started on talking about\n",
      "at the app development with llamps\n",
      "uh thank you Scott\n",
      "um Paul um so like there are a variety\n",
      "of models available uh both uh\n",
      "proprietary and open source so uh how\n",
      "best can we utilize them when we are\n",
      "actually using the power of llms in our\n",
      "applications so uh in order to be able\n",
      "to rightly put to production like\n",
      "productionize and llm and be able to use\n",
      "it to the full potential that uh that is\n",
      "where the real challenge lines because\n",
      "just using an ellipse uh like we all\n",
      "have been like using chat GPT and we\n",
      "know that it is like it's easy to just\n",
      "communicate to the bot available but\n",
      "then how to apply that to your use case\n",
      "to your Enterprise and that is where we\n",
      "will be looking at uh different aspects\n",
      "from that perspective so starting with\n",
      "if we have to look at the complete\n",
      "application development uh flow so first\n",
      "of all we would start with the\n",
      "Enterprise rise data so if you see here\n",
      "because you have the nlm but you want to\n",
      "augment the data of the element so that\n",
      "it is able to cater to your Enterprise\n",
      "needs and that is where the Enterprise\n",
      "data becomes important that is the raw\n",
      "data which gets you so again the data\n",
      "can be in different formats it can be at\n",
      "different places so we pass the data and\n",
      "in most cases uh since the volume of\n",
      "data would be huge so we would decide to\n",
      "use a vector database which is like a\n",
      "most convenient and efficient way to be\n",
      "able to store and then search over the\n",
      "data also so these embeddings of the\n",
      "data in whichever format it is would be\n",
      "stored in the vector database and be\n",
      "available for the models to use now uh\n",
      "once we start setting up our pipeline so\n",
      "if we think of this as a flow where the\n",
      "user starts asking a question how does\n",
      "that get resolved or uh\n",
      "responded by the complete uh\n",
      "application which comprises of the llm\n",
      "and then uh so it starts with two main\n",
      "aspects the prompted chain and the\n",
      "coolest chain The Prompt chain you know\n",
      "is the most like most important part of\n",
      "your how you're using your elements if\n",
      "you have\n",
      "um experience with Charity how well you\n",
      "can write the prompts your model will\n",
      "respond to you so that is where when you\n",
      "are actually applying this to an\n",
      "application you have to take care of\n",
      "um an aspect of standardization and a uh\n",
      "a templating so that is where we have uh\n",
      "prompt which gives you a structure of\n",
      "how you want your prompt to be and maybe\n",
      "some static text which will be part of\n",
      "your main prompt then you would want to\n",
      "augment the prongs with the extra data\n",
      "so this data could come from your vector\n",
      "database it could come from the web if\n",
      "you are using some like plugins or at\n",
      "web retriever so accordingly the data\n",
      "will get augmented and then the final\n",
      "prompt will be formulated and this may\n",
      "additionally so depending on so it's not\n",
      "like you would be using all the parts of\n",
      "it but in a in a full-fledged Enterprise\n",
      "application these aspects become\n",
      "necessary because when you are trying to\n",
      "use\n",
      "um llm you should do in the most uh you\n",
      "can say most structured and standardized\n",
      "way and that is where since this field\n",
      "is evolving of course there are new\n",
      "standards coming in but then uh this\n",
      "base standard and there are some\n",
      "Frameworks which have uh like made this\n",
      "easy for us as we try to develop a\n",
      "applications using llm so Frameworks\n",
      "like line chain and Haystack which help\n",
      "you integrate the model uh and also help\n",
      "to cater to these different aspects so\n",
      "whether it is a prompt chain a tool\n",
      "change a tool tools come into picture\n",
      "then you want to do something extra when\n",
      "you want to say uh so one example could\n",
      "be get data from say a web retriever so\n",
      "that could be a Search tool which gets\n",
      "added so similarly depending on the need\n",
      "of your Enterprise application you can\n",
      "have tools and there there is a list of\n",
      "tools available for Plankton chain and\n",
      "Lister\n",
      "then there can be a information search\n",
      "module so this would be the uh part\n",
      "where your framework will connect to the\n",
      "vector database and pass on your query\n",
      "to give the relevant response and\n",
      "further you can have a memory of a\n",
      "component so this is required in order\n",
      "to keep the context of the conversation\n",
      "so for example in line chain we have a\n",
      "concept of conversational memory wherein\n",
      "you like keep a track of the\n",
      "conversation so that as the user is\n",
      "communicating with the application or\n",
      "the bot or the uh so it keeps track of\n",
      "the say a set of previous\n",
      "conversations which have happened so\n",
      "that the next conversation would be in\n",
      "flow of that and again that could be\n",
      "structured in a way which suits as per\n",
      "the requirements so if it is a if it is\n",
      "a freshly new unrelated question you may\n",
      "not add it to them but only if you need\n",
      "to keep track of the conversation you\n",
      "may add it to them so that is up to the\n",
      "developer how you use these tools to\n",
      "make the best use of your element\n",
      "so finally making use of all these uh\n",
      "pipe this pipeline of the different\n",
      "nodes you can actually formulate your\n",
      "response and send it back to your uh\n",
      "user using the element so this is fed\n",
      "into the llm from where the response is\n",
      "generated so again\n",
      "um\n",
      "there uh the different tools there again\n",
      "it would be like the different document\n",
      "stores so\n",
      "um the different uh say\n",
      "any additional agents or tools which can\n",
      "be incorporated so making use of all\n",
      "this you can build a application\n",
      "and then\n",
      "so if we talk about the two Frameworks\n",
      "and there there are other Frameworks\n",
      "also but I have picked these two\n",
      "Frameworks as uh line chain is much more\n",
      "popular than you uh talk about open AI\n",
      "models and uh Haystack is another tool\n",
      "which has been uh like used with the\n",
      "older models also so now it has added\n",
      "open AI but it it uses the other models\n",
      "also and also it has some features which\n",
      "actually uh are not available in\n",
      "language so uh and they have their own\n",
      "advantage that's the reason I I have\n",
      "picked up both of these and if you look\n",
      "at each aspect of taking a model into\n",
      "production so starting with the llm\n",
      "support so whether the two framework is\n",
      "allowing you to connect to the LL and\n",
      "this is anyways like all the popular\n",
      "models\n",
      "[Music]\n",
      "are provided by these two and so uh it\n",
      "can be connected and used then coming to\n",
      "prompt templates and Engineering so\n",
      "again a very important aspect in using\n",
      "llms because prompt engineering is what\n",
      "uh like finally gives you the expected\n",
      "result and that's how you can\n",
      "um Because unless if you really have a\n",
      "requirement to find you prompts are the\n",
      "real power in your hand using which you\n",
      "can\n",
      "um get your job done\n",
      "so and\n",
      "um like there are multiple Concepts\n",
      "which are coming on how well you can use\n",
      "your prompts so be it uh like a Chain of\n",
      "Thought prompting where you like ask the\n",
      "model to break this uh\n",
      "task into multi-steps and then do it in\n",
      "the fashion of reasoning and applying\n",
      "the answer so uh and then there is a\n",
      "react methodology where you are forcing\n",
      "LM to do some reasoning and then nothing\n",
      "so there are different white papers on\n",
      "this and these Frameworks have actually\n",
      "provided you templates for uh in in line\n",
      "with these Concepts so be it react Chain\n",
      "of Thought then there is Action Plan\n",
      "Generation so where the model tells you\n",
      "like these are the things it will do to\n",
      "give you the response so\n",
      "so that actually perform uh improves the\n",
      "performance of your model if uh just\n",
      "imagine like giving the answer in just\n",
      "one go versus being able to reason and\n",
      "uh like think back and check back in\n",
      "your knowledge base and then give the\n",
      "answer so just like how we humans work\n",
      "so we are forcing the model to do the\n",
      "similar thing uh they're coming to\n",
      "process orchestration so again like when\n",
      "once you have your model your prompts\n",
      "ready your model is giving the results\n",
      "you would want a proper a workflow to be\n",
      "set up in how the different components\n",
      "of your pipeline are interacting and it\n",
      "is possible that in your complete\n",
      "application workflow there will be a\n",
      "need to invoke multiple elements because\n",
      "sometimes we would want to say go for a\n",
      "cheaper llm or a own version model for a\n",
      "simpler activity for which we need not\n",
      "go to charge GPT so accordingly we can\n",
      "actually orchestrate uh and have a\n",
      "chaining of uh different nodes or\n",
      "components which will perform different\n",
      "actions so there could be one node\n",
      "connecting to open AI to do say uh some\n",
      "question answering but there could be a\n",
      "separate node to just do the embedding\n",
      "strong maybe a lower level model so so\n",
      "the chains are the chains in line chain\n",
      "and Haystack has a concept of pipelines\n",
      "which try to achieve the same the\n",
      "process orchestration and\n",
      "then once you have your process of\n",
      "course very important thing is how\n",
      "you're getting your knowledge so you\n",
      "have to connect to say some data sources\n",
      "and get your data and maybe if your data\n",
      "is already infected database if you\n",
      "directly connect to it but then if your\n",
      "data is then some documents so you would\n",
      "want to bring it to a structure where\n",
      "you can easily query upon it so that is\n",
      "where you will fetch your data from\n",
      "these different document routers then\n",
      "you will do the processing maybe text\n",
      "splitting then converting to embeddings\n",
      "then finally uh loading into your\n",
      "documents tools so that is also provided\n",
      "by both of these Frameworks and it\n",
      "connects to almost of the popular Vector\n",
      "databases to give you the capability of\n",
      "question answer then uh the next thing\n",
      "of course question answering so there is\n",
      "a different flavor to how these two uh\n",
      "interact and give the response so uh\n",
      "with line chain you have like it queries\n",
      "the data then it passes on to the next\n",
      "you can say the next node of the\n",
      "pipeline or the chain to create the\n",
      "response\n",
      "reading the answer from the document or\n",
      "it is a retriever so the difference\n",
      "would be like retriever would actually\n",
      "retrieve the section of the document\n",
      "which is related so something like a\n",
      "similarity search and then you pass out\n",
      "to the pass on the retriever to the next\n",
      "uh node of your pipeline which would be\n",
      "a generator so generator would generate\n",
      "the response so accordingly like these\n",
      "are different ways of how you interact\n",
      "with your knowledge source and extract\n",
      "the data then if we uplook and\n",
      "deployment survey here\n",
      "um we can say that so Haystack has an\n",
      "edge here because it provides a rest API\n",
      "for many of the actions actually you can\n",
      "deploy your model and then you can also\n",
      "test it's you can evaluate so you have\n",
      "different apis to provide them\n",
      "then coming to agents and memories\n",
      "agents are a special type of\n",
      "um you can say modules which which are\n",
      "enabled by complex prompts and give you\n",
      "a certain type of behavior and you can\n",
      "attach tools on top of it so you have a\n",
      "concept of agents in both Lang chain and\n",
      "hairstyle and maybe I'll show you some\n",
      "some of the examples where how they\n",
      "interact and how their reason and give\n",
      "the answer\n",
      "also GPU integration can be provided in\n",
      "both these Frameworks there are other\n",
      "features like they have these utility\n",
      "packages which enable you to format the\n",
      "result or make some additional uh say\n",
      "queries to web searches and all and then\n",
      "they have a module for evaluation also\n",
      "which\n",
      "um so which gives the structure of how\n",
      "you would evaluate your model\n",
      "performance and\n",
      "so that you are able to measure and\n",
      "decide if there's a need for improvement\n",
      "and also be able to monitor in the round\n",
      "and finally use case wise also so both\n",
      "Lang chain and Haystack cater to all the\n",
      "common use cases which MLM provides\n",
      "additionally one thing which I saw in\n",
      "Haystack is our capability of annotation\n",
      "so it has an annotation uh like the\n",
      "portal here you can actually like name\n",
      "your data set level your data set in\n",
      "order to provide that as a evaluation\n",
      "data or as a test data for your model so\n",
      "that is\n",
      "um one feature which is that provides\n",
      "so if we look at all these aspects so\n",
      "these are all the different uh levels of\n",
      "how you or you're actually building an\n",
      "application using llm and with my my\n",
      "means of using these Frameworks you can\n",
      "actually bring a structure to your\n",
      "application and uh because these are all\n",
      "mature tools which have already done\n",
      "some work for you in a way that you can\n",
      "utilize the base and Achieve good\n",
      "results so it is always recommended to\n",
      "pick a framework and use it in your\n",
      "application\n",
      "now when you're using llms we\n",
      "um we need to remember that uh it it\n",
      "will not work immediately in the first\n",
      "case and there will be issues uh so\n",
      "there are issues related to latency so\n",
      "um models like charging PT and gpt4\n",
      "um they take they are slow as spot\n",
      "mentioned so so as we are using it we\n",
      "need to have a methodology of how best\n",
      "we can use it because they also provide\n",
      "ways of how you can say cater to the\n",
      "errors sometimes you get the rate limit\n",
      "error or say the\n",
      "open AI error so uh depending on you can\n",
      "actually have a retry mechanism to\n",
      "handle these errors and have a multiple\n",
      "uh retries before you actually fail the\n",
      "application because in a in a standard\n",
      "application you would want a mature\n",
      "behavior and that is what the app\n",
      "provides you to handle it in a smoother\n",
      "way and clean also other things like\n",
      "hallucination or if questions are not\n",
      "being properly answered if it's just\n",
      "saying that uh so a Dodge question is\n",
      "like uh it just says that I'm a model\n",
      "and I don't have the knowledge to answer\n",
      "the question or if there are any\n",
      "um changes to the prompt any toxicity or\n",
      "profanity any long-winded answers which\n",
      "are not as per expectation so how you\n",
      "can bring in control to these aspects\n",
      "again\n",
      "um whatever you do you can\n",
      "make use of these Frameworks as a bottom\n",
      "line and maybe I would repeat that just\n",
      "to make the importance of the Frameworks\n",
      "in all this\n",
      "so uh if we look at how we can avoid and\n",
      "make uh sorry avoid the errors avoid the\n",
      "problems with the llm and try to make\n",
      "the best use of it so using prompt\n",
      "Engineering in the right way is one very\n",
      "important aspect because in the prompt\n",
      "you can actually provide a structured\n",
      "instruction to the model on how it\n",
      "should perform what it should not do\n",
      "provide a context if there is a\n",
      "historical association with that\n",
      "knowledge chain or if there is a\n",
      "knowledge based uh data which you want\n",
      "to attach so that becomes your context\n",
      "and then\n",
      "you attach your question so instead of\n",
      "giving a plain question without any\n",
      "context where you leave it to the model\n",
      "to behave in its own way and that would\n",
      "lead to highly solution you can actually\n",
      "control it by giving the structure to\n",
      "your prom so that is why prompt\n",
      "engineering becomes very important also\n",
      "since uh you are looking at using the\n",
      "other Revenue Enterprise you would look\n",
      "at how you can adapt to your domain and\n",
      "that is where and how you could augment\n",
      "the knowledge and that is where the uh\n",
      "concept of uh like these Vector\n",
      "databases which you would use to augment\n",
      "the knowledge and then you would have to\n",
      "take care of feedback monitoring and\n",
      "continuous Improvement of your prompts\n",
      "and the how value of models behaving and\n",
      "finally you can also for issues like\n",
      "toxicity and profanity you can avoid\n",
      "those by applying guard rails which is\n",
      "like a python package which allows you\n",
      "to provide a\n",
      "um you can say\n",
      "language a real format where you can\n",
      "actually give specific validations you\n",
      "want to perform in the output before it\n",
      "is given back to the user and also maybe\n",
      "if you are not satisfied you can make up\n",
      "another call to the model and not send\n",
      "the response in the first time so that\n",
      "control can be added so with all these\n",
      "things you can actually control your\n",
      "Model Behavior and avoid uh\n",
      "hallucinations and uh you have to have\n",
      "an evaluation methodology because you\n",
      "will start small you will start maybe\n",
      "just by experimenting your problems and\n",
      "charity then you will have a proper\n",
      "model\n",
      "structured from defined then you will\n",
      "build your application around it you\n",
      "will add more data to test it and you\n",
      "will have to ensure that you are able to\n",
      "cover all aspects of the testing in\n",
      "order to actually be able to say that\n",
      "your model is working well in all and\n",
      "since it's the language model you are\n",
      "actually\n",
      "um of course if your use case is a very\n",
      "limited one but usually you would want a\n",
      "human-like conversation so there uh the\n",
      "the plethora of variations is actually\n",
      "Limitless so that is where uh you have\n",
      "to really keep evaluating and keep\n",
      "validating your model and you can have\n",
      "some evaluation metrics like\n",
      "um have a like a predetermined uh\n",
      "expected responses and have a matching\n",
      "against it to see how similar they are\n",
      "against the expected ones or you can as\n",
      "the yellow level llm itself to rate if\n",
      "this answer is good enough or you can\n",
      "have uh say some old answer which you\n",
      "want to compare and see if your new\n",
      "answer is uh like the comparable to the\n",
      "answer which was expected and then you\n",
      "can have other static mathematics like\n",
      "you can again use the llm to give a\n",
      "rating to your answer so things like\n",
      "that and this is something where you\n",
      "will have to say be a little uh you can\n",
      "say Innovative and apply it to your use\n",
      "case based on the uh needs of the\n",
      "behavior\n",
      "but as you are actually using it you\n",
      "have to remember that you are in a\n",
      "continuous cycle of uh development\n",
      "testing and deployment and then taking\n",
      "your feedback again testing and again uh\n",
      "deploying so this cycle keeps continuing\n",
      "because there will be variations and\n",
      "there will be things so have a mechanism\n",
      "of feedback so that you are able to\n",
      "incorporate the test data improve your\n",
      "prompts to give a better performance\n",
      "also there are baby scenarios where you\n",
      "would want to find tuning so you would\n",
      "identify those scenarios and follow the\n",
      "fine tuning books and the same cycle\n",
      "would work when you are doing it as a\n",
      "developer then you do it as you are a\n",
      "proper team testing you give it for uit\n",
      "so every cycle where you test and\n",
      "finally when you give it to the end user\n",
      "so uh you have to keep repeating and\n",
      "ensuring that you're collecting feedback\n",
      "so that your your model is improving and\n",
      "never stagnating so uh with this I I\n",
      "would quickly show you\n",
      "um few examples of Lang chain\n",
      "so uh basically I just wanted to give\n",
      "you a view of how uh using these\n",
      "Frameworks you can bring and you can\n",
      "quickly develop your code and reuse the\n",
      "structured uh nodes which these\n",
      "Frameworks provide in order to bring a\n",
      "good uh overall behavior of your\n",
      "application so if you look at this\n",
      "hairstyle this is a haystack pipeline\n",
      "using pine pot so you you would set your\n",
      "environment and you have a document\n",
      "store which you would import from your\n",
      "Haystack you would set your parameters\n",
      "then again hashtag provides you a\n",
      "logging capability where you can\n",
      "actually set the logging level whether\n",
      "it is debug or info and then you would\n",
      "uh so you have different utils of how\n",
      "you want to collect uh say fetch your\n",
      "articles from HTTP or you have to\n",
      "combine documents so you can make use of\n",
      "these utils then you have the nodes so\n",
      "again prompt node is a very important\n",
      "notebook which allows you to\n",
      "um like consolidate the capability and\n",
      "behavior and attach a prompt of your\n",
      "choice and then connect to your llm and\n",
      "be able to respond to your required\n",
      "so and then prompt is sorry node is one\n",
      "part of it and then putting these node\n",
      "together you would form a pipeline so\n",
      "again uh here there are two types of\n",
      "pipelines so it could be a document\n",
      "search pipeline again so of course there\n",
      "are many other pipelines and the idea is\n",
      "like these pipelines are already like\n",
      "set up with some nodes which have a\n",
      "predefined behavior so if you have a\n",
      "similar way of it you can actually get\n",
      "up and running by just importing these\n",
      "pipelines and maybe certain\n",
      "modifications as per unit so for this\n",
      "example like we picked up some uh policy\n",
      "documents and we converted into say a\n",
      "document store then created a retriever\n",
      "so uh like retriever is uh a component\n",
      "or unmod so this is an embedding\n",
      "retriever which actually would\n",
      "store the embeddings for the given\n",
      "document store so here we are using the\n",
      "and uh\n",
      "so this gets stored in your document\n",
      "store which is the point in this case so\n",
      "accordingly you can use different and\n",
      "then you can apply the pipeline so here\n",
      "uh I've used two pipelines so this is\n",
      "the document search pipeline which would\n",
      "only search the document and give you\n",
      "the result so if that is the requirement\n",
      "you can use this so you can see that you\n",
      "pass the query and uh the retriever is\n",
      "able to respond so and then if you're\n",
      "using this generative QA pipeline so\n",
      "it's like a question answering pipeline\n",
      "which will take a retriever and a\n",
      "generator so retriever will actually\n",
      "retrieve the data from the document\n",
      "store and pass it to the generator and\n",
      "then generator will generate the\n",
      "response so accordingly like this is one\n",
      "example and maybe I'll just uh so if you\n",
      "see here the the first one which is the\n",
      "document search pipeline so it it gives\n",
      "the um the document basically from where\n",
      "it got the data so tell me something\n",
      "about the working hours policy and it is\n",
      "able to fetch the content and the name\n",
      "of the document and suppose if this is\n",
      "the this is the generative question\n",
      "answer pipeline so here it is actually\n",
      "giving you a proper answer because it\n",
      "has the Retriever and the generator so\n",
      "similarly if we look at the next example\n",
      "so this is using land shape with deep\n",
      "link so deep lake is another kind of\n",
      "vector store it is actually\n",
      "um\n",
      "it is a combination of data Lake and\n",
      "Vector stored so gives you more\n",
      "capabilities on your vector store\n",
      "another\n",
      "so this example where I have taken a\n",
      "message text or message text is like a\n",
      "text with some conversation which the\n",
      "user has with the chatbot and then we\n",
      "are trying to ask questions on top of\n",
      "that so if your organization has like a\n",
      "chatbot and there's lot of data getting\n",
      "collected if you want to derive value\n",
      "out of it so this could be a useful so\n",
      "what we have used is the deep clean so\n",
      "again the syntax will be slightly\n",
      "different but the idea is similar so and\n",
      "additionally in line chain we are using\n",
      "a text splitter so obviously your data\n",
      "may be huge so you can actually chunk it\n",
      "and then split and then load it into\n",
      "your vector database and then you can\n",
      "use your say embeddings\n",
      "to load it into your data set inside the\n",
      "data Lake and then finally you set up a\n",
      "retriever so you're giving like to check\n",
      "the distance metric is a cosine\n",
      "similarity and the number of arguments\n",
      "or the top case over here so accordingly\n",
      "your QA uh your retriever will fetch the\n",
      "data so here we are using the line chain\n",
      "retrieval Q8 chain and you can give a\n",
      "chain type so stuff is like it will give\n",
      "all the response there are other\n",
      "variations here like mapreduce if you\n",
      "want to achieve a summarized so you can\n",
      "actually try out these different\n",
      "variations depending on your use case\n",
      "and apply the most suitable one and then\n",
      "you can see like for this query\n",
      "so oh yeah this was the question I\n",
      "entered so what is overall sentiment and\n",
      "it it actually tries to analyze and give\n",
      "you a response of what were the main\n",
      "issues and the conversation was helpful\n",
      "and the main issues were true\n",
      "so\n",
      "the product description or things like\n",
      "that so this it is deriving that from\n",
      "the conversation so similarly there are\n",
      "other examples like this one is using a\n",
      "vector tape so uh I will quickly show\n",
      "this one so this is an agent which is\n",
      "using a web retriever\n",
      "so basically uh if you uh when you are\n",
      "using an agent which actually tries to\n",
      "induce a concept of reasoning and acting\n",
      "which so this prompt template actually\n",
      "uses the few short react reactors are\n",
      "freezing and freezing an Arctic and uh\n",
      "just to show you how this uh so in the\n",
      "prompt we have given it like how it\n",
      "should break the problem and try to\n",
      "answer the question instead of directly\n",
      "answering the question because the\n",
      "answer because the question is not a\n",
      "straightforward one so there is a some\n",
      "amount of freezing which needs to be and\n",
      "that is how the the model behaves and it\n",
      "tries to break the problem and gets the\n",
      "answer so let me show you some examples\n",
      "here so I try to confuse the model by\n",
      "asking it who was the youngest Indian PM\n",
      "who stayed in power for the longest\n",
      "donation so actually there are two\n",
      "questions here youngest and longest\n",
      "duration now so the model was the bit\n",
      "confused it he tried to apply a lot of\n",
      "reasoning so if we see here it it\n",
      "actually tries to get data from\n",
      "different this is using a web retriever\n",
      "so it's getting data from the web it is\n",
      "trying to apply uh logic just like so\n",
      "the input is this and then this is the\n",
      "observation so it is saying like Okay\n",
      "this was how what it thought and then\n",
      "finally did what tool did it use it used\n",
      "as such and then finally it learned this\n",
      "so it will actually show you how it is\n",
      "using the information and then finally\n",
      "with all this observation and Analysis\n",
      "it gave a response that so Rajiv Gandhi\n",
      "was the\n",
      "uh youngest\n",
      "with the longest Direction so\n",
      "so this is the some these are some\n",
      "examples of how you can use the\n",
      "capabilities provided by these\n",
      "integration Frameworks so now I will\n",
      "hand over to shubham to talk about the\n",
      "different models you can use and see\n",
      "some real use cases\n",
      "thanks evolution\n",
      "hi everyone I will be soon sharing my\n",
      "screen\n",
      "I hope my screen is visible\n",
      "so let me get started so as of Lasha\n",
      "mentioned in this section I will be\n",
      "discussing the apps which have been made\n",
      "using different llms I'll also show do a\n",
      "quick demo on the usage of different\n",
      "llms and I'll also uh delve a bit deeper\n",
      "on the choice on the various parameters\n",
      "that you need to consider while making a\n",
      "choice particularly with regards to open\n",
      "source elements\n",
      "so to start with uh\n",
      "let's talk about the apps which are\n",
      "already out there which make use of\n",
      "these large language models and as most\n",
      "of you are anyway aware the two most\n",
      "prominent apps of our times which are\n",
      "uh or rather three most prominent apps\n",
      "of this time which are making headwinds\n",
      "are chat GPT a bird and they are being\n",
      "AI now\n",
      "while they are powered by different\n",
      "models but it's not the fact that they\n",
      "are just powered by different models\n",
      "which makes them different so of course\n",
      "chargity is powered by a gbd 3.5 turbo\n",
      "and you have the gpd4 equivalent as well\n",
      "as on so in charge every plus you can\n",
      "use type gbd4 on the other side you have\n",
      "Bud which is powered by Lambda a\n",
      "language model for dialogue applications\n",
      "so Lambda is also as optimized at least\n",
      "meant to be as optimized for\n",
      "conversation applications as turbos was\n",
      "meant to be however if you compare the\n",
      "two applications they differ in terms of\n",
      "their user experience Bard is considered\n",
      "to be better in terms of user experience\n",
      "but is considered uh\n",
      "less good compared to chat GPD when it\n",
      "comes to summarizing and paragraph\n",
      "writing so there are areas where Bard is\n",
      "better for example Bard has access to\n",
      "live data on internet of course it's by\n",
      "Google so it does have however chat GPT\n",
      "is trying to catch up on that by\n",
      "introducing plugins\n",
      "we have Bing AI which is powered by gpt4\n",
      "so bingia is a Microsoft Search tool and\n",
      "it is using gbd4 to give the best\n",
      "possible results of analysis on\n",
      "different questions which come up so it\n",
      "is more than just a Search tool like\n",
      "Google which was like just indexing the\n",
      "results it also does that but then it\n",
      "because it has uh gpd3 and dvd4 at the\n",
      "backbone so the way it produces those\n",
      "results based on your queries is\n",
      "different\n",
      "uh on top of that right or rather\n",
      "following up to these applications is\n",
      "cloud so as Scott was mentioning in the\n",
      "beginning Claude is one of the biggest\n",
      "combinators to open a models uh so open\n",
      "am always like gpd4 they are considered\n",
      "quite nice of course they are quite nice\n",
      "their performance is quite good gpd4\n",
      "currently stands as the best model but\n",
      "then when you go to the niche set of\n",
      "models for example when you go to the\n",
      "models made currently uh being made by\n",
      "anthropic which was which is actually by\n",
      "X open engineers and which is backed by\n",
      "Google you realize that what they are\n",
      "doing is really cool this cloud is\n",
      "actually the backbone of\n",
      "Claude is quantum Computing they have a\n",
      "Quantum Computing backed uh structure so\n",
      "the infrastructure is driven by that and\n",
      "cloud is meant to be a model which is\n",
      "expected to ingest huge amount of data\n",
      "so it can ingest even a book of yours in\n",
      "a few seconds so its context size is\n",
      "like 75 000 words and if you really want\n",
      "to build applications which are Fusion\n",
      "which crosses huge amount of data and\n",
      "also context aware and they are aware of\n",
      "some ethical context cloud is considered\n",
      "as one of the best models so it's of\n",
      "course it's not open so it's not\n",
      "available to everybody right now uh so\n",
      "it's very selective but they are moving\n",
      "slowly and gradually so\n",
      "on one side it can process much more\n",
      "data it is very faster because of its\n",
      "condom Quantum Computing backbone on the\n",
      "other side it is also a thick somewhere\n",
      "it is uh it has a constitutional AI so\n",
      "they use the word phrase\n",
      "constitutionally I even describe Claude\n",
      "so it it has it's also this a sense of\n",
      "models and ethics is embedded so it is\n",
      "meant to be helpful assistant which is\n",
      "meant to prevent those kinds of Errors\n",
      "which other models do have to be\n",
      "explicitly uh prompted not to do\n",
      "now let's come to applications which are\n",
      "uh kind of custom applications so what I\n",
      "show here is a dual impro Max app so\n",
      "this app is meant to be an education app\n",
      "and in this app this this app has been\n",
      "existing for quite long they said they\n",
      "have added two more features to it\n",
      "recently explain my answer uh is one of\n",
      "them where whatever answer the app gives\n",
      "this education app gives language\n",
      "learning another uh uh uh education\n",
      "subjects are taught here uh whatever\n",
      "answer the application the gbd4 backbone\n",
      "the gbd4 model underline enables the\n",
      "user to also get an explanation for\n",
      "those answers similarly the user will\n",
      "also be able to interact with the\n",
      "different players uh or the different\n",
      "characters in this with the help of our\n",
      "role play uh feature which is empowered\n",
      "by child which is powered by gp4\n",
      "coming to the next one\n",
      "wait a second\n",
      "yes so the next thing which I show here\n",
      "is be my eyes so as you would guess by\n",
      "the name it's a volunteer for blind\n",
      "people so it uses GPT Force image\n",
      "processing capabilities gpd4 as uh Scott\n",
      "would have also I have talked about in\n",
      "that perspective uh it's not just as you\n",
      "also know it's not just a text\n",
      "processing engine it also processes\n",
      "images it looks at images understands\n",
      "and looks at a context even in this in\n",
      "this case the context is quite important\n",
      "and give suggestions so this is one of\n",
      "the major uh use cases of gbd4 where\n",
      "gbd3 for example or 3.5 would not be\n",
      "helpful per se another important app uh\n",
      "which is quite popular is the Khan\n",
      "Academy which is using gpd4 and in this\n",
      "also the objective is to customize\n",
      "learning to different users and as a\n",
      "blusher was mentioning there are cases\n",
      "where you would need to even fine-tune\n",
      "models to bring them to such a level of\n",
      "quality where uh you could get a\n",
      "personalized education or or not\n",
      "necessarily personalized also always but\n",
      "maybe education cater to us at certain\n",
      "group of people personalized to a group\n",
      "of people if not a person but then uh\n",
      "with models like gpd4 and prompt\n",
      "Engineering in the background the actual\n",
      "power is anyway realized so you need not\n",
      "really fine tune gpd4 or 3.5 cannot be\n",
      "fine during either\n",
      "next is stripe which is uh also using\n",
      "gpd4 so gpd4 in this application in this\n",
      "payment related application is helping\n",
      "under one hand customers which are able\n",
      "better able to understand the context of\n",
      "the business they are able to ask\n",
      "different kinds of questions and uh get\n",
      "appropriate responses for them having\n",
      "ensuring a good customer experience on\n",
      "the other side it's also helping the\n",
      "business in detecting different kinds of\n",
      "frauds by analyzing by doing data\n",
      "analytics on the inputs which they get\n",
      "on the app\n",
      "we've uh wanted to talk about llm apps\n",
      "not just gpd3 or gpd4 apps per se so\n",
      "here I also present a section of apps\n",
      "from cohere so cohere has been there for\n",
      "quite long it has been there for almost\n",
      "two to three years and uh it it's an\n",
      "issue again uh it's not it's uh it's\n",
      "different from open end it's certainly\n",
      "not that popular but if you go to the\n",
      "coherence website you will see that\n",
      "there are individual models dedicated to\n",
      "individual tasks like embeddings\n",
      "creation toxicity detection\n",
      "summarization Etc whereas in case of\n",
      "open AI you don't have dedicated models\n",
      "for each of those tasks naturally when\n",
      "you have dedicated models for something\n",
      "right which are kind of customized for\n",
      "that you can expect their performance to\n",
      "be better however uh it's not as if you\n",
      "can't do it using open AI or using maybe\n",
      "within opening using GPT is such that\n",
      "when you use those models you\n",
      "necessarily have to do some effort in\n",
      "certain cases as a make some investment\n",
      "of time in certain cases so uh I want to\n",
      "be able to go through each one of them\n",
      "because it's a huge list but then uh for\n",
      "example what you see here uh uh the\n",
      "first one is a multi-lingual book so\n",
      "this is meant to be an AI powered search\n",
      "on the content of the book so it's not\n",
      "something which you cannot do really\n",
      "using uh uh open AI with Langston but\n",
      "then uh because in this particular case\n",
      "when the app was being built the maker\n",
      "of the app found even cohere to be a\n",
      "good candidate for building so they went\n",
      "ahead and built it and so there are\n",
      "other apps also which have been built\n",
      "using cohere interestingly if you look\n",
      "at the different apps which are out\n",
      "there while there are as Scott was\n",
      "mentioning there are language models\n",
      "which can't be uh used in commercial\n",
      "applications that said developers still\n",
      "use those models to make their own kinds\n",
      "of applications for use by themselves or\n",
      "in houses\n",
      "I would like to give here a short demo\n",
      "just to explain how these different\n",
      "kinds of models can be used in\n",
      "applications and also just to kind of uh\n",
      "make you appreciate where uh and how you\n",
      "can make the choice\n",
      "I will be using our Enterprise\n",
      "conversation AI framework for that which\n",
      "we call it is a short form for\n",
      "Enterprise conversation AI and what I\n",
      "want to show here is the trade-off which\n",
      "we have to make in terms of choosing\n",
      "different models so uh as Scott was\n",
      "mentioning in the beginning on one side\n",
      "you have the accuracy of the model on\n",
      "the other side you have speed they don't\n",
      "always map one to one uh they are not so\n",
      "I wouldn't say they are inversely\n",
      "related now would I say they are\n",
      "directly proportionally related but so\n",
      "you have to consider models it also\n",
      "depends whether you're considering a\n",
      "profit free model or an open source\n",
      "model then you have to consider whether\n",
      "uh\n",
      "uh the quality of the answers uh are\n",
      "good enough for your use case it's not\n",
      "as there are models which are higher in\n",
      "quality better in quality but it's not\n",
      "always the case as if every app you are\n",
      "designing needs that kind of quality for\n",
      "example if you are doing some kind of\n",
      "binary classification which is very\n",
      "simplistic I don't think you need to use\n",
      "gb4 for that or for that matter GPT 3.5\n",
      "for that or for that matter GPT uh for\n",
      "for that matter devancy for that you\n",
      "could rather do it with Babbage of\n",
      "theory in if your use case of a certain\n",
      "kind so here let me start interacting\n",
      "with different models uh so what I what\n",
      "I'm doing right now the way I have coded\n",
      "app is so I start with the name of the\n",
      "model I ask it some question I see the\n",
      "response and uh let's talk through as it\n",
      "goes\n",
      "so in our previous webinars we have\n",
      "extensively uh\n",
      "demoed applications built with gbd 3.5\n",
      "which is chat GPT API which is powering\n",
      "charged API so we have demoed\n",
      "applications we're using chat GPD here I\n",
      "would like to take a step back and talk\n",
      "about elements in general\n",
      "so I'm trying to ask devency003 which is\n",
      "actually texted and see 003 uh about uh\n",
      "say com Quantum computing\n",
      "Quantum Computing I also asked about its\n",
      "applications I just want to answer the\n",
      "question to be relatively more\n",
      "complicated now uh\n",
      "so it's 11c003 and I ask about these two\n",
      "things\n",
      "so first of all you see it's anyway\n",
      "taking some time to give the answer now\n",
      "uh the fact is if I were to use chat GPD\n",
      "API for that for people who have used\n",
      "chat GPT API and even know that it takes\n",
      "a long time to give you responses so uh\n",
      "it's not as if it's not uh uh we're set\n",
      "outside for sure but then as open AI is\n",
      "anyways scaling it up uh scaling up the\n",
      "infrastructure those things are meant to\n",
      "slow down as in the the delays are meant\n",
      "to slow down the app is expected to\n",
      "become faster but uh let's leave that\n",
      "aside for the time being so what I'm\n",
      "trying to say is you will encounter\n",
      "slowness in responses in some cases\n",
      "anyhow because of the demand of these\n",
      "models now the answer which you get from\n",
      "here is the definition of quantum\n",
      "Computing and you have applications of\n",
      "quantum Computing and you have some one\n",
      "two three four five six six points\n",
      "related to that and these are broad\n",
      "points now okay so this is not a bad\n",
      "answer in fact it's a good answer but\n",
      "let me ask the same question to DaVinci\n",
      "zero zero two and what's the difference\n",
      "between devices 003 and zero zero two uh\n",
      "this is 003 is based on rlhf\n",
      "reinforcement learning through human\n",
      "feedback uh so it has a human feedback\n",
      "component to it whereas in case of uh\n",
      "DaVinci zero zero two you don't have\n",
      "it's it's based on fine tuned uh uh\n",
      "input so let me do the same for MSC 02\n",
      "see the answer given by the model uh\n",
      "is relatively shorter but then\n",
      "would you call it a wrong answer it's\n",
      "not a wrong answer person it's just that\n",
      "the model is not as detailed as you\n",
      "would like it to be however if you were\n",
      "using this model to if you were building\n",
      "an app for children would you really\n",
      "need a kind of complexity the kind of\n",
      "detailed uh grass that DaVinci is going\n",
      "to provide it's not required right in\n",
      "fact in some cases it is much more\n",
      "important that you use a model which\n",
      "provides a brief overview and in a very\n",
      "simplistic fashion and that is what\n",
      "devices use YouTube is giving to you but\n",
      "even here you realize that devancy took\n",
      "some time now let's ask the same\n",
      "question to Curie\n",
      "this is the answer which we received\n",
      "from the model one thing which I would\n",
      "like to point right away instead this\n",
      "answer is faster so the speed is higher\n",
      "in this case and again\n",
      "while this answer may be qualitatively\n",
      "is indeed qualitatively uh words\n",
      "compared to the one given by Dimensions\n",
      "003 it is an equation so for maybe a\n",
      "consumption by children or maybe\n",
      "consumption by younger audience so uh\n",
      "while models like gpd4 or GB 3.5 uh are\n",
      "indeed better what I'm trying to say is\n",
      "it's not as if you required it kind of\n",
      "quality for every use case and for\n",
      "example if you if you were to ask this\n",
      "question to Ada well it does case will\n",
      "be hilarious because it's a complicated\n",
      "equation further but let's look at its\n",
      "speed\n",
      "so this this was pretty fast however\n",
      "when you looked at the answer to the\n",
      "question you realize uh it is not even\n",
      "answering the question properly we asked\n",
      "about uh the applications of uh Quantum\n",
      "Computing and it just talks about uh uh\n",
      "what is the current Quantum computer\n",
      "what is a bit and what is a qubit and uh\n",
      "well it talks about one kind of uh use\n",
      "of quantum Computing but it's not it's a\n",
      "tangential answer however if you were to\n",
      "ask it something else what's the\n",
      "computer stuff like that right it would\n",
      "give it awesome uh which is accurate\n",
      "because anyway it's a very basic stuff\n",
      "so this is one what I'm trying to show\n",
      "here is you have models which give birth\n",
      "answers however those verse answers are\n",
      "retained uh returned faster but when you\n",
      "just try to extrapolate it so if you are\n",
      "using a model like Adele if you're using\n",
      "a model like query or Babbage so I\n",
      "didn't show babage but then Babbage is\n",
      "in between uh since these models can be\n",
      "fine-tuned and when you fine-tune these\n",
      "models you actually make them usable for\n",
      "your specific requirement if you want to\n",
      "build a classifier using Ada uh so for\n",
      "your system or if you want to build a\n",
      "classifier using uh well for your use\n",
      "case you want to build a classifier you\n",
      "want to build maybe some kind of uh q a\n",
      "generator again based on your set of\n",
      "documents where again you don't want\n",
      "that depth of information you could use\n",
      "these models you could fine tune these\n",
      "models so your fine-united is still\n",
      "cheaper than a Devon C but it would be\n",
      "way faster so the speed is essentially a\n",
      "Criterion here and why is it a Criterion\n",
      "so in this case it is fine if the\n",
      "response is returned slowly however if\n",
      "there were n number of processes which\n",
      "were dependent on this response and you\n",
      "had n number of calls being made to\n",
      "these models you can just assume that\n",
      "your application would even time out so\n",
      "there is no question there now this was\n",
      "this was for uh\n",
      "now let me just go to some open source\n",
      "models so I'll start with let me just\n",
      "make a disclaimer so because I've seen\n",
      "recently let open as I make calls to\n",
      "open am these open source models some of\n",
      "them are really taking a lot of time so\n",
      "we may take some time to get answers but\n",
      "mean well I'll give you a walk through\n",
      "uh the code so in this case I'm going to\n",
      "ask to start with uh say a stability AI\n",
      "so as Scott was mentioning stability a\n",
      "is one of the important contenders for\n",
      "uh usage in competition for competition\n",
      "usage from the perspective of Open\n",
      "Source models from the category of Open\n",
      "Source models so I asked the same\n",
      "question to stability Ai and let's see\n",
      "what it does what's answered it gives\n",
      "bin value generates the answer I would\n",
      "like to give about proof of the code and\n",
      "as to how it could be used for even\n",
      "other models and more important than how\n",
      "it could be used for other models I want\n",
      "to just emphasize on even the different\n",
      "kinds of uh\n",
      "well Frameworks which are then when I\n",
      "talk about Frameworks it's not\n",
      "necessarily in terms of a living\n",
      "Frameworks like launching and Lang chain\n",
      "and his check is also in terms of uh\n",
      "Technologies which allow you to make\n",
      "more efficient use of these models via\n",
      "infrastructure that they offer so\n",
      "as you can see on my screen so this is\n",
      "uh the code of rasa in here I have of\n",
      "course abstracted out the keys and so on\n",
      "but uh\n",
      "if I start from the relevant section\n",
      "which is line number seven because prior\n",
      "to that you have uh code which is\n",
      "related to rasa I start with open\n",
      "another code in line number seven so in\n",
      "this case I'm using Lang chin and I'm\n",
      "importing large language models from\n",
      "Langston and here what I import is open\n",
      "AI import cohere I import AI to one I\n",
      "import uh so ai21 is is a provider of\n",
      "Jurassic models I'll also try that\n",
      "shortly I import Goods AI input vertex\n",
      "you know uh what is a quite uh good\n",
      "about who's AI whose AI Builds on top of\n",
      "open AI only as in so the answers it\n",
      "returns are using open AI models only I\n",
      "mean unless you really want to change\n",
      "that however it provides you the results\n",
      "at a cheaper rate so in some cases at\n",
      "around 30 percent of the price so it\n",
      "provides uh that infrastructure which uh\n",
      "is utilized in such a way that you your\n",
      "output your post is cheap your outputs\n",
      "are cheaper as in they have produced it\n",
      "as lesser cost similarly you have vertex\n",
      "here now vertex AI is on Google Cloud\n",
      "platform uh on Google Cloud platform\n",
      "certainly you are not using open AI you\n",
      "are using pump so when you make use of\n",
      "what if you want to make use of palm\n",
      "model Pathways language model and you\n",
      "really don't want to go into the depth\n",
      "of it in terms of for example writing\n",
      "python code per se right you could have\n",
      "it on vertex Ai and you could actually\n",
      "make use of vertex say in Lang change so\n",
      "uh it's quite simple so what you have is\n",
      "for example if you were to use vertex\n",
      "here or Google now let me again Mission\n",
      "these are not models per se these are\n",
      "Frameworks which give you some\n",
      "competitive advantage over other models\n",
      "maybe in terms of pricing maybe in terms\n",
      "of infrastructure maybe in terms of\n",
      "speed and of course some of them are\n",
      "indeed models like cohere so what you\n",
      "need to do is you need to go to uh uh\n",
      "the of course respective providers you\n",
      "need to get your API key from there and\n",
      "then you just in these all are actually\n",
      "uh\n",
      "uh kind of embedded with Langston so\n",
      "they they are Integrations in Langston\n",
      "which already provided for these so you\n",
      "could simply provide your open API the\n",
      "respective API key open API Q Google\n",
      "so on for coherence on for cloud and you\n",
      "could just invoke your respective uh\n",
      "base model with the help of uh these\n",
      "classes now you could of course provide\n",
      "more parameters to these if you want to\n",
      "choose a particular kind of model or if\n",
      "you want to choose a particular\n",
      "temperature Etc but at that side that's\n",
      "the the basic format in which you would\n",
      "invoke these models or systems is this\n",
      "and uh here as I was trying to mention I\n",
      "have Devon c03 02 invoked and I also\n",
      "invoke Curie and NADA and Babbage and uh\n",
      "what I've also tried to invoke is other\n",
      "open source models which either come\n",
      "from uh hugging phase so the flying T5\n",
      "model is a very powerful model so T5 has\n",
      "been there for quite long I mean people\n",
      "generally when they talk about\n",
      "generative AI this Zoom generative AI\n",
      "begins with foreign\n",
      "for a long time you had T5 for a long\n",
      "duration so flan is in optimized to a\n",
      "fine tune version of that but then uh\n",
      "what I'm trying to indicate is a\n",
      "generative is not restricted to GPT\n",
      "that's what so you have other models by\n",
      "Google and other providers so here I'm\n",
      "trying to use uh plan model I've invoked\n",
      "stability AI model I haven't booked the\n",
      "dolly model provided by data bricks and\n",
      "then the very famous uh open source\n",
      "equivalent of gbd3 and it's quite easy\n",
      "so you provide your parameters you\n",
      "provide the repo ID along with other\n",
      "parameters how much Max how much lens\n",
      "you want what's the temperature you want\n",
      "Etc and then you simply make a call now\n",
      "making a call uh when you make the call\n",
      "depending on what the kind of task you\n",
      "want to do uh you define the respective\n",
      "template for it for example as a blusher\n",
      "was mentioning so even if you have to\n",
      "answer a question you don't answer the\n",
      "question directly I mean you you can\n",
      "tell the model how you should it should\n",
      "answer the question and in this case uh\n",
      "I'm providing the template where I am\n",
      "asking it to think step by step and then\n",
      "answer so if you have a complicated\n",
      "question it tries to answer uh bits by\n",
      "bit so in some models will see that\n",
      "happening in all models that doesn't\n",
      "happen because in some models the\n",
      "pre-trained base actually takes uh\n",
      "precedence over that prompt and the\n",
      "results you get are from the pre-trained\n",
      "base uh they are not so much customizers\n",
      "for your phone but if when you see for\n",
      "open source models in some cases you\n",
      "will see the results are customized with\n",
      "a prompt you give uh you uh provide a\n",
      "prompt template where you specify the\n",
      "instruction\n",
      "here so I'm taking the input from the\n",
      "actions from the custom uh default\n",
      "action default fallback and here uh this\n",
      "is a simplistic one which I just put to\n",
      "illustrate to explicitly uh illustrate\n",
      "what is going on here so whatever model\n",
      "I'm getting so I'm passing instructions\n",
      "uh each instruction each question which\n",
      "I am passing is preceded by the model\n",
      "name so uh in any other application that\n",
      "could be a drop down so it's a\n",
      "conversational app so I decided just to\n",
      "keep it this way but then I'm invoking\n",
      "the respective model and more\n",
      "importantly then whatever model is\n",
      "invoked uh goes to the llm is stored in\n",
      "llm and that is stored in the variable\n",
      "Lang chain sorry LMC and then what the\n",
      "question which I ask is pass to this\n",
      "agent using llmc.run and it generates\n",
      "answer from then it answer comes under\n",
      "front end now uh let me see whether that\n",
      "stability I give down\n",
      "I mean you have it provided from the uh\n",
      "hugging phase\n",
      "uh Hub right so as I was showing in the\n",
      "code\n",
      "this so if you look at the answer the\n",
      "answer is uh I would say uh\n",
      "reasonable so it's not as detailed as WC\n",
      "it's comparable to curious response it\n",
      "did take time but then of course uh\n",
      "these are models which are in this case\n",
      "I'm using hungry pics and uh if one were\n",
      "to for example in shorted a prepared\n",
      "infrastructure Etc gets provisioned uh\n",
      "from the other side right if you could\n",
      "scale up your uh account in Residence\n",
      "right or as the use usage of the models\n",
      "indexes and this would be faster so\n",
      "whatever I'm trying to say is this is a\n",
      "pre-trained model which is giving a\n",
      "decent response now let me ask another\n",
      "question and this time we'll ask a\n",
      "question too\n",
      "dolly\n",
      "which is by databricks and let it\n",
      "generates response and then I'll go to\n",
      "uh some other stuff which I have to\n",
      "cover\n",
      "wait a minute\n",
      "so I'm trying to do a comparative\n",
      "analysis so it's natural that the same\n",
      "equation will be asked\n",
      "so as uh I'll come to that in a short\n",
      "while but before that I would like to\n",
      "give a very uh quick\n",
      "walkthrough of another very important\n",
      "concept which comes here and this is\n",
      "also related to the choice of the\n",
      "language models which we have to do and\n",
      "that is what is known as uh holistic\n",
      "uh evaluation of large language models\n",
      "or in short what is known as Helm this\n",
      "will take a short while to load but let\n",
      "me mention that uh the number of large\n",
      "language models has been increasing at a\n",
      "dramatic Pace over the last many many\n",
      "months now and it's difficult to count\n",
      "those models there there were times like\n",
      "six months ago or eight months ago when\n",
      "you when you could count the models on\n",
      "your fingers at least the quote unquote\n",
      "popular models on your fingers but uh\n",
      "right now it's not even that so if even\n",
      "if you were to ask how many models\n",
      "Google provides right you start counting\n",
      "you have Palm you have Lambda you have\n",
      "plan T5 you have T5 you have others\n",
      "similar so if you look at remember the\n",
      "slides which\n",
      "Scott washing that talks about the sheer\n",
      "number and that was just indicative\n",
      "because the most important models were\n",
      "considered there but then you have a\n",
      "bigger a huge number now it's not as if\n",
      "those models have uh\n",
      "uniform performance so their performance\n",
      "has increased over time and if you were\n",
      "really to choose which model is bad\n",
      "better so of course uh as of now gpd4 is\n",
      "the best model\n",
      "starting when you go to the next stage\n",
      "you have gbd 3.5 uh close on the heels\n",
      "is coming uh Cloud but again cloud has\n",
      "been tested only by a small section of\n",
      "the users so uh its responses are\n",
      "considered more natural more intuitive\n",
      "uh more driven by ethics but then\n",
      "you don't have that comparison then\n",
      "extensively with the model so a Layman\n",
      "can't say it Claude is better however\n",
      "when it comes to all other models or\n",
      "rather not all but really a good number\n",
      "of models popular models right uh there\n",
      "has been a framework which has been\n",
      "arrived at by uh a group of people from\n",
      "Stanford so this is the helm framework\n",
      "holistic evaluation of large language\n",
      "models of language models and they have\n",
      "considered a different uh attributes\n",
      "there and\n",
      "in an actual application these\n",
      "attributes matter right so what they\n",
      "have considered is accuracy calibration\n",
      "error which is which is a marker of your\n",
      "uncertainty in the model the robustness\n",
      "so you change the different kinds of\n",
      "input you change can change the kind of\n",
      "inputs you're providing you provide the\n",
      "same input in different ways right\n",
      "what's the quality of the response in\n",
      "that perspective uh the fairness of the\n",
      "model the bias and the model the\n",
      "toxicity in the model I I'm not planning\n",
      "to go through each of these models and\n",
      "how they are performing in that person\n",
      "uh in this webinar but what I'm trying\n",
      "to indicate is that different models\n",
      "perform well in different aspects for\n",
      "example uh while you see a Dev so let me\n",
      "also mention that this doesn't include\n",
      "gbd4 and GB 3.5 because this Benchmark\n",
      "was made in early January and was\n",
      "probably there was a paper which was\n",
      "published in early January and gbd4\n",
      "anyways post uh March so you won't have\n",
      "it here but this is kind of indicative\n",
      "of the other models of the predecessor\n",
      "models and I'm sure the the group will\n",
      "be including 3.5 and uh four as well so\n",
      "they have already included GPS 3.5 so\n",
      "the results are not in this graph\n",
      "because that's not the way they have\n",
      "published in the paper but uh four is\n",
      "there to be integrated but what I'm\n",
      "trying to indicate is that when you look\n",
      "at accuracy you have texted agencies use\n",
      "YouTube which is uh uh at the best uh\n",
      "perform which is the best performing\n",
      "well uh when you look at a calibration\n",
      "error you do get a calibration error uh\n",
      "maximum in case of texted as usual so\n",
      "written set into feature of course I\n",
      "told you right that editor gives\n",
      "childish answers but then when you it's\n",
      "not as if the other one on the extreme\n",
      "is Devon c003 it's odinis is used you to\n",
      "stop uh if you look at the robustness\n",
      "revenue performs better but close in the\n",
      "uses anthropic models which are related\n",
      "to Cloud if you look at fairness again\n",
      "you have a similar kind of situation but\n",
      "when you go into the deeper levels right\n",
      "when you when you look at the ordering\n",
      "the ordering changes so in one case\n",
      "Turing is uh this uh Turing analogy is\n",
      "performing better net okay so open is\n",
      "performing better when you look at the\n",
      "bias you find it open source models like\n",
      "uh gpdg right couldn't be quite High\n",
      "advice and it also depends on what kind\n",
      "of data you were trained on uh so and so\n",
      "on for toxicity so one has to look at\n",
      "each of these parameters uh while\n",
      "judging whether a particular model is\n",
      "relevant for this scenario so the helm\n",
      "people who worked at this index they\n",
      "consider different scenarios there was a\n",
      "huge long list of scenarios but these\n",
      "are five these are the six major\n",
      "scenarios which were considered and uh\n",
      "with again without necessarily going to\n",
      "the detail of each one of them but still\n",
      "trying to give you a feeling of the\n",
      "importance of these different uh kinds\n",
      "of evaluations so even when you look at\n",
      "a basic question answering scenario\n",
      "which is what generally chat is right so\n",
      "you ask something it's a question and\n",
      "you give it an answer what these people\n",
      "found at uh certain models for example\n",
      "like coheres right which is anyway not\n",
      "that popular but it's an issue uh\n",
      "category of models they have performed\n",
      "uh better or at least marginally better\n",
      "than set in open a models so while in\n",
      "fact in this case you see that text at\n",
      "nc002 is performing better and x703 now\n",
      "the fact is uh\n",
      "the way these mod 2 models zero zero two\n",
      "and zero three have been arrived at is\n",
      "different there is no logic per se that\n",
      "003 is always expected to be better in\n",
      "all benchmarks right so it's not as as\n",
      "of zero zero three was not better on in\n",
      "general it's just that when you take the\n",
      "average zero zero two has been found to\n",
      "be better and uh I'll also come to what\n",
      "are the data sets on which they were\n",
      "evaluated similarly when you look at\n",
      "robustness fairness for question\n",
      "answering the results which you get are\n",
      "different so uh query is biased is uh\n",
      "uh comparable to Yellow spies but then\n",
      "and so on for texted minces but uh if\n",
      "you were to look at it relatively from\n",
      "the uh\n",
      "uh consideration of or the perspective\n",
      "of certain documents and you would see a\n",
      "different picture so if you were to for\n",
      "example do the same analysis for\n",
      "information retrieval now information\n",
      "retrieval is on a set of documents so uh\n",
      "here also you have to consider accuracy\n",
      "robustness and fairness you get one\n",
      "another index for that and when you look\n",
      "at summarization uh capability uh of\n",
      "course uh in summarization capability\n",
      "summarization metrics hold most\n",
      "importance but it's it's also important\n",
      "that whatever summaries you are getting\n",
      "right it should not be a bias summary it\n",
      "should not selectively consider it is\n",
      "considered certain personalities or\n",
      "certain kinds of personalities or\n",
      "demographics Etc so that uh analysis is\n",
      "done at this level as well similarly you\n",
      "do that for sentiment analysis and you\n",
      "do that for toxicity detection\n",
      "so what is important here to consider\n",
      "that when this evaluation was done on\n",
      "different data sets so what you have on\n",
      "the x-axis is different data sets uh mmu\n",
      "bull queue narrative etc etc you find\n",
      "that it's not as if open source models\n",
      "or closed Source models so those in\n",
      "between write limited models right\n",
      "restricted models they are per se better\n",
      "one category is per se better than the\n",
      "other category I mean there are cases\n",
      "where you find that uh they're quite\n",
      "comparable if you look at the IMDb right\n",
      "the performance of these three models\n",
      "classes of models is quite comparable so\n",
      "it's not as if when you're building your\n",
      "application you can simply disconsider\n",
      "kind of data which you have in fact it's\n",
      "a it's a bad size so the if your kind of\n",
      "data is matching with a particular\n",
      "category which these have for example\n",
      "have been referred uh with a particular\n",
      "category which matches with any of these\n",
      "categories as have been referred to here\n",
      "and it's quite important to consider the\n",
      "accuracy for a certain kind of model so\n",
      "similarly when you look at uh cumulative\n",
      "accuracy uh well this accuracy this was\n",
      "actually uh at the cluster level as in\n",
      "at a category level of Open Source\n",
      "limited models in closed Source models\n",
      "but when you consider at a level of\n",
      "individual models you again see red\n",
      "accuracy is different for different data\n",
      "sets\n",
      "uh so what I was trying to emphasize\n",
      "this and this is a let me also mention\n",
      "this is a very well established uh\n",
      "benchmarks so uh the the so I have tried\n",
      "to indicate the extensiveness of that by\n",
      "just also referring explicitly to the\n",
      "paper which was produced uh for this as\n",
      "a result of the evaluation which was\n",
      "done here and the holistic evaluation\n",
      "has uh considered all models well when I\n",
      "say all I do mean the prominent still\n",
      "but then uh what with the all in in the\n",
      "sentence is meant to indicate models\n",
      "from different categories open source\n",
      "closed Source proprietary as an even\n",
      "within a closed Source they just don't\n",
      "limit to open air they go to cohere\n",
      "right they look at anthropics models and\n",
      "they have given extensive elevation so\n",
      "what I've tried to show was only the\n",
      "best performance uh uh on the parameters\n",
      "but in case you were interested on each\n",
      "of these metrics right in case for\n",
      "example you wanted to look at accuracy\n",
      "on a certain kind of data set so even\n",
      "though I say devices 003 is most\n",
      "accurate but then there are cases where\n",
      "you find that 0 0 2 is more accurate as\n",
      "in fact in in the averaging scenario\n",
      "right for the uh for the case which I\n",
      "considered zero zero two was found to be\n",
      "better it was for a question answering\n",
      "scenario this is not a question\n",
      "answering scenario person so uh this\n",
      "Matrix shows let's say certain models\n",
      "are a better uh performing in certain\n",
      "scenarios similarly if you look at\n",
      "robustness or uh maybe uh the other uh\n",
      "scenarios which they have considered so\n",
      "on one side they have scenarios which\n",
      "you have tested for all models but then\n",
      "there are some special targeted\n",
      "scenarios which they have tested for a\n",
      "specific set of models you need to\n",
      "consider what kind of data source you\n",
      "have what kind of requirement you have\n",
      "you need to just check which are the\n",
      "best models performing as per uh this\n",
      "Benchmark because it is a neutral\n",
      "Benchmark of course if you go to open\n",
      "ai's website it will show you results if\n",
      "you're able to gpd40g but it's pretty\n",
      "similarly if you were to go on\n",
      "anthropics it would show your favorable\n",
      "results so there is no unbiased opinion\n",
      "there however if you were to look at\n",
      "this metrics you will get unbiased\n",
      "opinion and while if you want to build\n",
      "something very quickly if you want to do\n",
      "a prototyping right if you want to do a\n",
      "prototype just go for gbd4 check it out\n",
      "whether it's even capable of being built\n",
      "but that said once you have settled down\n",
      "for that once you really start want to\n",
      "build it and you want to explore\n",
      "different cases options which are faster\n",
      "maybe cheaper Etc and which are still\n",
      "more accurate right it's important that\n",
      "you consider this metric so uh let me\n",
      "just see whether uh\n",
      "uh so okay so I got answer from Dolly as\n",
      "hopefully uh but this is what I see here\n",
      "so you see even Dolly's response is good\n",
      "enough right so it does add uh unrelated\n",
      "information for example it talks about\n",
      "when was the uh first quantum computer\n",
      "built and this answer is not expected to\n",
      "be given by uh gbd3 or gbd4 because it\n",
      "doesn't provide unnecessary information\n",
      "but then that said the response to which\n",
      "you are getting here is still reliving\n",
      "to your question so as an a part of the\n",
      "response is relevant to your question so\n",
      "uh this is what I had uh from the\n",
      "perspective of uh applications of large\n",
      "language models the different uh ways in\n",
      "which you can rather use different kinds\n",
      "of models so here we did discuss Lang\n",
      "chain uh uh I discussed Lang Syne\n",
      "Centric uh in cooperation of these more\n",
      "integration of these models but what I\n",
      "also try to emphasize was that when you\n",
      "talk about integration of these models\n",
      "it's not as if you just need to consider\n",
      "the models per se you you these\n",
      "Frameworks also allow you to incorporate\n",
      "different uh I would say uh Solutions\n",
      "which provide you other enhancements\n",
      "over your model so you have for example\n",
      "deep infra which provides you a separate\n",
      "a different kind of infrastructure you\n",
      "have booze AI which provides you uh\n",
      "cheaper models even though you still end\n",
      "up using open air models so uh or\n",
      "cheaper price even though you still end\n",
      "up using open a models and then I also\n",
      "try to indicate that uh when you have a\n",
      "use case which you want to implement\n",
      "using llms it's best that you go by the\n",
      "uh\n",
      "Benchmark which is uh kind of a neutral\n",
      "and it it so turns out that there are\n",
      "models which are less toxic which are\n",
      "more robust which are less biased which\n",
      "are more fair and for a certain kind of\n",
      "data set and you should use those models\n",
      "so thanks uh for the patient listening\n",
      "and now we'll be happy to answer any\n",
      "questions\n",
      "thank you shubham we do have a few and I\n",
      "suppose the responsibly visible to use\n",
      "but I'll just read them out\n",
      "uh we have a few from hitesh goyal how\n",
      "will you handle the situation where\n",
      "different prompts are required depending\n",
      "on the data that comes out from Vector\n",
      "how typically is this handled\n",
      "how will you handle that the situation\n",
      "we are different I'm just reading\n",
      "through it different prompts are\n",
      "required depending on data comes out\n",
      "from the vector how typically that is\n",
      "Central or right C uh okay so maybe I'm\n",
      "just trying to confirm my understanding\n",
      "here but if it is not yet please type it\n",
      "out so your point is that uh maybe you\n",
      "have a document processing use case and\n",
      "you know that your model will give you\n",
      "out give out different kinds of answers\n",
      "and you need to selectively provide\n",
      "different inputs based on the kind of\n",
      "answers now uh as we have done in our\n",
      "use cases we know a priori what is that\n",
      "variety of answers you can get of course\n",
      "it doesn't mean that we know each and\n",
      "every possible answer that comes out but\n",
      "we can broadly categorize the response\n",
      "into different uh\n",
      "classes and for each class we can indeed\n",
      "build a kind of classifier where we\n",
      "invoke that and then ask the model to\n",
      "behave in a certain way for example if\n",
      "you are fetching answers from uh say a\n",
      "website which is scraped out and well\n",
      "you have saved 100 Pages there and you\n",
      "asked a question now in some uh Pages\n",
      "you will not have uh answers only in\n",
      "uh text format you will also have uh\n",
      "tags Etc if they were not extracted\n",
      "properly even if they were extracted\n",
      "probably will have numbers Etc now you\n",
      "have numeric data which is coming from a\n",
      "page and uh you don't want to handle it\n",
      "just like that item you want to remove\n",
      "that data you want to handle it in a\n",
      "specific format but you know that you\n",
      "are going to have this kind of data\n",
      "right so even when you will receive the\n",
      "prompt from your you will receive the\n",
      "response from your large language model\n",
      "you know that it will it can belong to\n",
      "certain categories and you will add a\n",
      "subsequent condition there that if a\n",
      "response is of a certain kind then you\n",
      "do so and so so what I'm trying to\n",
      "indicate is even though the responses\n",
      "will be of different kind but still they\n",
      "should fall in some class and you could\n",
      "use a\n",
      "llm based classifier for that so llm\n",
      "based classifiers are generally more\n",
      "optimal because uh you know these are\n",
      "complex tasks and you could then have\n",
      "customized Logic on top of it\n",
      "so next is any point of view on layout\n",
      "of your PDF person well uh see we have\n",
      "different uh\n",
      "applications where we have done that for\n",
      "example I think you were there in the\n",
      "last webinar as well so uh where we\n",
      "showed parsing of medical documents\n",
      "which were in PDF and the answers this\n",
      "came they were quite good we also have a\n",
      "resume parsing application which\n",
      "processes PDF files now the thing is uh\n",
      "if you look at uh for example GB 3.5\n",
      "models this is not meant to be layout\n",
      "sensitive in the sense that it will\n",
      "automatically consider that uh certain\n",
      "section is belonging from a certain\n",
      "block of text so it depends on your\n",
      "extractor so let me mention that uh\n",
      "these models are\n",
      "if and if you ignore gpd4 gbd4 reach\n",
      "your images but your images it's\n",
      "different to read images but it's\n",
      "reading images is not in the same sense\n",
      "as reading a PDF document right what I'm\n",
      "trying to say is\n",
      "when you pass your document to any of\n",
      "these models you first changes the\n",
      "document through some kind of loader and\n",
      "that kind of loader is agnostic of the\n",
      "kind of llm you are using for parsing\n",
      "now if you look at Lang chain uh the\n",
      "loaders which are\n",
      "publicized on Lama index page for\n",
      "example I have seen that they are quite\n",
      "drop us loaders so when you use those\n",
      "loaders the text which\n",
      "so what I'm trying to say is that layout\n",
      "sensitivity comes from the robust\n",
      "loaders you use not from the language\n",
      "models person\n",
      "lens and also audio manipulate training\n",
      "Cycles if we can do correct toxic and\n",
      "appropriate responses well we did\n",
      "discuss one of the\n",
      "most important ways of quantifying\n",
      "accuracy which is help and you can look\n",
      "into\n",
      "more details of the evaluation there but\n",
      "how do you on how do you manipulate\n",
      "training Cycles if you can to correct\n",
      "toxic and appropriate resources\n",
      "unfortunately what we have seen see\n",
      "right now the state of llms or this\n",
      "generative Airfield is such where\n",
      "you don't know a priori how many\n",
      "training Cycles will lead to a certain\n",
      "kind of output so\n",
      "there is a manual intervention required\n",
      "in most cases even if you were to send\n",
      "set some kind of a benchmark which you\n",
      "would like to use for automating\n",
      "uh the results you would still have to\n",
      "manually review it because of the kind\n",
      "of confidence there is in lymphs right\n",
      "now so I mean just consider the fact\n",
      "that llms have certain elements have\n",
      "known to be toxic right and when the\n",
      "llms are anyway known to be toxic uh the\n",
      "very analysis of toxicity of the data\n",
      "produced by those llms the the Criterion\n",
      "which you are using for analyzing the\n",
      "toxicity right even you you need to\n",
      "consider that with a pinch of salt so\n",
      "what I am saying is uh when you do this\n",
      "toxicity analysis first of all it's\n",
      "difficult to fully automate the process\n",
      "and you need to do it repeatedly and the\n",
      "number of training cycles per se it\n",
      "varies so if you for example if just\n",
      "talk let's talk about fine tuning of a\n",
      "model right so you have a simple task\n",
      "where you have a pre-trained model and\n",
      "you want to make it learn a particular\n",
      "lingo or maybe brand voice of a\n",
      "particular brand and why super\n",
      "particular brand and then you find you\n",
      "in the model how many iterations do you\n",
      "require for that well it depends on the\n",
      "amount of data you have passed to the\n",
      "model it depends on the kind of accuracy\n",
      "you want it depends on the kind of uh so\n",
      "when I say the kind of data of course\n",
      "means the uh quantity of data for sure\n",
      "so I mean whether you are passing it say\n",
      "a book of information or say 10 pages of\n",
      "a website but it also depends on the\n",
      "domain uh specific nature of the data\n",
      "right whether your data even has terms\n",
      "which are falling in a different domain\n",
      "altogether right for example in most\n",
      "businesses a certain term will not mean\n",
      "what it means in real life or maybe what\n",
      "it means to people uh speaking of it\n",
      "casually so unfortunately even as we\n",
      "have looked at it in Greater detail we\n",
      "have seen that whenever it comes to fine\n",
      "tuning whenever it comes to duration\n",
      "unlike in conventional machine learning\n",
      "where you have very calibrated metrics\n",
      "which you could use as thresholds to cut\n",
      "off the iteration process in case of\n",
      "large language models at least as of now\n",
      "you don't need that thing doesn't work\n",
      "so it's more likely to lead to wrong\n",
      "answers\n",
      "so if it is about manipulating training\n",
      "cycle in terms of how do you make it\n",
      "more accurate more less toxic more\n",
      "appropriate responses that that option\n",
      "there there are uh prompts which you can\n",
      "design where you explicitly ask the\n",
      "model to uh\n",
      "uh constantly check for higher levels of\n",
      "sorry certain levels of toxicity for\n",
      "example uh it's funny to say I mean but\n",
      "anyway it's worth it so if you have a\n",
      "paragraph and you want to understand a\n",
      "toxicity you could just ask the model to\n",
      "rank the paragraph on toxicity on a\n",
      "scale of 0 to 10 and it will give you a\n",
      "rank to it but now suppose your toxicity\n",
      "is reduced you again Ask it to give a\n",
      "rank it gives you that there will be a\n",
      "time when it is not going to change its\n",
      "rank maybe it is ranking it at two out\n",
      "of ten right but then you still want to\n",
      "rank it lower now you won't ask it to\n",
      "just analyze intoxicity right you would\n",
      "ask it for subtle attributes maybe\n",
      "you'll ask it for uh\n",
      "inclusivity and toxicity so there are\n",
      "people who for example will consider uh\n",
      "using gender specific language also is\n",
      "toxic right so what I'm trying to say is\n",
      "you will add more layers to toxicity to\n",
      "actually make the model still identify\n",
      "certain elements as toxic\n",
      "sure so we'll send the slides\n",
      "definitely\n",
      "yes so we will be sharing the recording\n",
      "of This webinar along with a link to\n",
      "these slides with everyone who has\n",
      "registered I am attended this session so\n",
      "yes that will definitely happen\n",
      "and it's been a long sessions and I\n",
      "suppose I hope we have answered all your\n",
      "questions and doubts so thank you\n",
      "everyone once again for joining us today\n",
      "and I hope we continue this Association\n",
      "going forward thank you everyone\n",
      "thanks everyone thank you\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "youtube_url = \"https://www.youtube.com/watch?v=1FhuvIuIIvg&list=PLBZRs2RzeAlr99JPvD5swEFi3eUwRGME2&index=9\"\n",
    "\n",
    "# Extract video ID with regex\n",
    "video_id_regex = r'(?:v=|\\/)([0-9A-Za-z_-]{11})'\n",
    "match = re.search(video_id_regex, youtube_url)\n",
    "\n",
    "if match:\n",
    "    video_id = match.group(1)\n",
    "else:\n",
    "    raise ValueError(\"No valid video ID found in the URL.\")\n",
    "\n",
    "# Fetch transcript\n",
    "try:\n",
    "    transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "    # Extract text\n",
    "    text_list = [entry['text'] for entry in transcript]\n",
    "    transcript_text = '\\n'.join(text_list)\n",
    "    print(transcript_text)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

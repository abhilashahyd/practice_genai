{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "openapi_key = os.environ[\"OPENAI_API_KEY\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Aria (Indian)\n",
      "2. Brooklyn (American)\n",
      "3. Xiu (Chinese)\n",
      "4. Kavya (Nepali)\n",
      "5. Zara (Indian)\n",
      "6. Harper (American)\n",
      "7. Ling (Chinese)\n",
      "8. Maya (Nepali)\n",
      "9. Avani (Indian)\n",
      "10. Savannah (American)\n",
      "11. Mei (Chinese)\n",
      "12. Anjali (Nepali)\n",
      "13. Amara (Indian)\n",
      "14. Scarlett (American)\n",
      "15. Li (Chinese)\n",
      "16. Sita (Nepali)\n",
      "17. Ishani (Indian)\n",
      "18. Kennedy (American)\n",
      "19. Jing (Chinese)\n",
      "20. Rohini (Nepali) \n",
      "\n",
      "1. Kailash (Indian)\n",
      "2. Hudson (American)\n",
      "3. Zhi (Chinese)\n",
      "4. Arjun (Indian)\n",
      "5. Maverick (American)\n",
      "6. Liang (Chinese)\n",
      "7. Aryan (Indian)\n",
      "8. Phoenix (American)\n",
      "9. Wei (Chinese)\n",
      "10. Aarav (Indian)\n",
      "11. Kingston (American)\n",
      "12. Jin (Chinese)\n",
      "13. Rohan (Indian)\n",
      "14. Orion (American)\n",
      "15. Tao (Chinese)\n",
      "16. Sahil (Indian)\n",
      "17. Lincoln (American)\n",
      "18. Xander (Chinese)\n",
      "19. Advait (Indian)\n",
      "20. Sterling (American)\n",
      "21. Kai (Chinese)\n",
      "22. Aarush (Indian)\n",
      "23. Atlas (American)\n",
      "24. Hao (Chinese)\n",
      "25. Aryan (Nepali)\n",
      "26. Asher (American)\n",
      "27. Qi (Chinese)\n",
      "28. Dev (Indian)\n",
      "29. Beckham (American)\n",
      "30. Ming (Chinese)\n",
      "\n",
      "\n",
      "\n",
      "1. Kailash (Indian)\n",
      "2. Hudson (American)\n",
      "3. Zhi (Chinese)\n",
      "4. Arjun (Indian)\n",
      "5. Maverick (American)\n",
      "6. Liang (Chinese)\n",
      "7. Aryan (Indian)\n",
      "8. Phoenix (American)\n",
      "9. Wei (Chinese)\n",
      "10. Aarav (Indian)\n",
      "11. Kingston (American)\n",
      "12. Jin (Chinese)\n",
      "13. Rohan (Indian)\n",
      "14. Orion (American)\n",
      "15. Tao (Chinese)\n",
      "16. Sahil (Indian)\n",
      "17. Lincoln (American)\n",
      "18. Xander (Chinese)\n",
      "19. Advait (Indian)\n",
      "20. Sterling (American)\n",
      "21. Kai (Chinese)\n",
      "22. Aarush (Indian)\n",
      "23. Atlas (American)\n",
      "24. Hao (Chinese)\n",
      "25. Aryan (Nepali)\n",
      "26. Asher (American)\n",
      "27. Qi (Chinese)\n",
      "28. Dev (Indian)\n",
      "29. Beckham (American)\n",
      "30. Ming (Chinese)\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature = 0.6)\n",
    "name = llm(\"i want to bahy girls name indian, American , Chine , Nepal. Suggest a fancy different name .\")\n",
    "name1 = llm(\"i want to bahy boys both name indian, American , Chine , Nepal. Suggest a fancy different name .\")\n",
    "print(name,name1)\n",
    "print()\n",
    "print(name1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nanhi Deo\\AppData\\Roaming\\Python\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import time\n",
    "\n",
    "def echo(message, history, system_prompt, tokens):\n",
    "    response = f\"System prompt: {system_prompt}\\n Message: {message}.\"\n",
    "    for i in range(min(len(response), int(tokens))):\n",
    "        time.sleep(0.05)\n",
    "        yield response[: i + 1]\n",
    "\n",
    "demo = gr.ChatInterface(\n",
    "    echo,\n",
    "    type=\"messages\",\n",
    "    additional_inputs=[\n",
    "        gr.Textbox(\"You are helpful AI.\", label=\"System Prompt\"),\n",
    "        gr.Slider(10, 100),\n",
    "    ],\n",
    ")\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_context(query, top_k_results):\n",
    "    context = query + \"\\n\"\n",
    "    for idx, row in top_k_results.iterrows():\n",
    "        context += f\"Document {idx}: {row['document_column']}\\n\"\n",
    "    return context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nanhi Deo\\AppData\\Roaming\\Python\\Python311\\site-packages\\gradio\\queueing.py\", line 622, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Nanhi Deo\\AppData\\Roaming\\Python\\Python311\\site-packages\\gradio\\route_utils.py\", line 323, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Nanhi Deo\\AppData\\Roaming\\Python\\Python311\\site-packages\\gradio\\blocks.py\", line 2014, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Nanhi Deo\\AppData\\Roaming\\Python\\Python311\\site-packages\\gradio\\blocks.py\", line 1579, in call_function\n",
      "    prediction = await utils.async_iteration(iterator)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Nanhi Deo\\AppData\\Roaming\\Python\\Python311\\site-packages\\gradio\\utils.py\", line 691, in async_iteration\n",
      "    return await anext(iterator)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Nanhi Deo\\AppData\\Roaming\\Python\\Python311\\site-packages\\gradio\\utils.py\", line 796, in asyncgen_wrapper\n",
      "    response = await iterator.__anext__()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Nanhi Deo\\AppData\\Roaming\\Python\\Python311\\site-packages\\gradio\\chat_interface.py\", line 667, in _stream_fn\n",
      "    first_response = await async_iteration(generator)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Nanhi Deo\\AppData\\Roaming\\Python\\Python311\\site-packages\\gradio\\utils.py\", line 691, in async_iteration\n",
      "    return await anext(iterator)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Nanhi Deo\\AppData\\Roaming\\Python\\Python311\\site-packages\\gradio\\utils.py\", line 685, in __anext__\n",
      "    return await anyio.to_thread.run_sync(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Nanhi Deo\\AppData\\Roaming\\Python\\Python311\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Nanhi Deo\\AppData\\Roaming\\Python\\Python311\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2405, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Nanhi Deo\\AppData\\Roaming\\Python\\Python311\\site-packages\\anyio\\_backends\\_asyncio.py\", line 914, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Nanhi Deo\\AppData\\Roaming\\Python\\Python311\\site-packages\\gradio\\utils.py\", line 668, in run_sync_iterator_async\n",
      "    return next(iterator)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Nanhi Deo\\AppData\\Local\\Temp\\ipykernel_16176\\3523540758.py\", line 6, in echo\n",
      "    for i in range(min(len(response), tokens)):\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: 'float' object cannot be interpreted as an integer\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import time\n",
    "\n",
    "def echo(message, history, system_prompt, tokens):\n",
    "    response = f\"System prompt: {system_prompt}\\nMessage: {message}.\"\n",
    "    for i in range(min(len(response), tokens)):\n",
    "        time.sleep(0.05)\n",
    "        yield response[: i + 1]\n",
    "\n",
    "demo = gr.ChatInterface(\n",
    "    fn=echo,\n",
    "    type=\"messages\",\n",
    "    additional_inputs=[\n",
    "        gr.Textbox(\"You are a helpful AI.\", label=\"System Prompt\"),\n",
    "        gr.Slider(10, 100, label=\"Max Tokens\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "demo.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
